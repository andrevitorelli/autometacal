{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5aac55-fd22-4d0f-b827-b62f3a0d2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, re, os, sys\n",
    "\n",
    "# GPU picking\n",
    "# http://stackoverflow.com/a/41638727/419116\n",
    "# Nvidia-smi GPU memory parsing.\n",
    "# Tested on nvidia-smi 370.23\n",
    "\n",
    "def run_command(cmd):\n",
    "    \"\"\"Run command, return output as string.\"\"\"\n",
    "    \n",
    "    output = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True).communicate()[0]\n",
    "    return output.decode(\"ascii\")\n",
    "\n",
    "def list_available_gpus():\n",
    "    \"\"\"Returns list of available GPU ids.\"\"\"\n",
    "    \n",
    "    output = run_command(\"nvidia-smi -L\")\n",
    "    # lines of the form GPU 0: TITAN X\n",
    "    gpu_regex = re.compile(r\"GPU (?P<gpu_id>\\d+):\")\n",
    "    result = []\n",
    "    for line in output.strip().split(\"\\n\"):\n",
    "        m = gpu_regex.match(line)\n",
    "        assert m, \"Couldnt parse \"+line\n",
    "        result.append(int(m.group(\"gpu_id\")))\n",
    "    return result\n",
    "\n",
    "def gpu_memory_map():\n",
    "    \"\"\"Returns map of GPU id to memory allocated on that GPU.\"\"\"\n",
    "\n",
    "    output = run_command(\"nvidia-smi\")\n",
    "    gpu_output = output[output.find(\"GPU Memory\"):]\n",
    "    # lines of the form\n",
    "    # |    0      8734    C   python                                       11705MiB |\n",
    "    memory_regex = re.compile(r\"[|]\\s+?(?P<gpu_id>\\d+)\\D+?(?P<pid>\\d+).+[ ](?P<gpu_memory>\\d+)MiB\")\n",
    "    rows = gpu_output.split(\"\\n\")\n",
    "    result = {gpu_id: 0 for gpu_id in list_available_gpus()}\n",
    "    for row in gpu_output.split(\"\\n\"):\n",
    "        m = memory_regex.search(row)\n",
    "        if not m:\n",
    "            continue\n",
    "        gpu_id = int(m.group(\"gpu_id\"))\n",
    "        gpu_memory = int(m.group(\"gpu_memory\"))\n",
    "        result[gpu_id] += gpu_memory\n",
    "    return result\n",
    "\n",
    "def pick_gpu_lowest_memory():\n",
    "    \"\"\"Returns GPU with the least allocated memory\"\"\"\n",
    "\n",
    "    memory_gpu_map = [(memory, gpu_id) for (gpu_id, memory) in gpu_memory_map().items()]\n",
    "    best_memory, best_gpu = sorted(memory_gpu_map)[0]\n",
    "    return best_gpu\n",
    "\n",
    "def setup_one_gpu():\n",
    "    assert not 'tensorflow' in sys.modules, \"GPU setup must happen before importing TensorFlow\"\n",
    "    gpu_id = pick_gpu_lowest_memory()\n",
    "    print(\"Picking GPU \"+str(gpu_id))\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "def setup_no_gpu():\n",
    "    if 'tensorflow' in sys.modules:\n",
    "        print(\"Warning, GPU setup must happen before importing TensorFlow\")\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d9acf5-b55d-418e-b22d-12867b99a5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_gpu_lowest_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e426797a-2e25-468d-b921-df6ff1788ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2961b25-0b73-44f4-9fae-f7b75277cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4, 1: 11883, 2: 301}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_memory_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918b9bbf-8591-4b2b-86b5-a2506652156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8ff350-1ad6-4708-9c43-0f3c2d52a8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29baba1a-0c7c-468b-992d-7ec4ddf450a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12187, 308, 7390]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51136972-16b3-42a7-a5f3-55a1713a9dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n",
      "Name: /physical_device:GPU:1   Type: GPU\n",
      "Name: /physical_device:GPU:2   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e077a2d2-853e-4da7-9a2a-e43e28a53c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu0=gpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efef29f5-9480-4101-9cda-4f9d18f21e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function PhysicalDevice.index(value, start=0, stop=9223372036854775807, /)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac030ab8-90c2-452c-9b88-973cdf4e7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2208753-15e2-43e6-a166-fe56c157b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([  1.       ,   5.0612245,   9.122449 ,  13.183674 ,\n",
       "              17.244898 ,  21.306122 ,  25.367346 ,  29.428572 ,\n",
       "              33.489796 ,  37.55102  ,  41.612244 ,  45.673466 ,\n",
       "              49.73469  ,  53.79592  ,  57.857143 ,  61.918365 ,\n",
       "              65.97959  ,  70.04082  ,  74.10204  ,  78.16326  ,\n",
       "              82.22449  ,  86.28571  ,  90.34693  ,  94.40816  ,\n",
       "              98.46938  , 102.53062  , 106.59184  , 110.65306  ,\n",
       "             114.71429  , 118.77551  , 122.83673  , 126.89796  ,\n",
       "             130.95918  , 135.02042  , 139.08163  , 143.14287  ,\n",
       "             147.20409  , 151.2653   , 155.32652  , 159.38776  ,\n",
       "             163.44897  , 167.51021  , 171.57143  , 175.63266  ,\n",
       "             179.69386  , 183.7551   , 187.81631  , 191.87755  ,\n",
       "             195.93877  , 200.       ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linspace(1,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879b697-bbf2-468c-b026-b58fab7d9e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
