{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f66627-0ecf-417e-8519-dc5824cb2747",
   "metadata": {},
   "source": [
    "# PSF Experiment 2.0 - Moments + shape noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34db291e-9142-4861-9195-f7d4500dc4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd95363-9d3f-40c4-a65e-5ea08590a60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "#this is us\n",
    "import autometacal as amc\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "#...vs them!\n",
    "import ngmix\n",
    "import galsim\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9adc5cc-ab73-417c-8580-ddf36564d75a",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4bc7b7-bc58-4209-9d16-0a97dde18d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_psf =  array([0.01,0.0],dtype='float32')\n",
    "rng = np.random.RandomState(31415)\n",
    "stamp_size = 51\n",
    "batch_size = 800\n",
    "noise_level = 1e-5\n",
    "shape_noise = 0\n",
    "psf_noise_level = noise_level/1000\n",
    "scale = 0.263\n",
    "ncpus = 48\n",
    "results_folder = \"Results/amc_vs_ngmix\"\n",
    "settings_name = \"anisotropic_psf_1em6_shape_noise\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e484f58-be4b-4d96-90bd-b6cad56a53fa",
   "metadata": {},
   "source": [
    "## Get to the Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df463745-e1d5-4887-b207-6859e5499789",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= tfds.load('GalGen/small_stamp_100k')\n",
    "data = data['train'].cache()\n",
    "data = data.batch(batch_size)\n",
    "data = data.repeat()\n",
    "data = data.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736a7062-e064-424c-90d6-4ca7526555e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchit = data.as_numpy_iterator()\n",
    "onebatch = batchit.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51213b13-07b1-4bb8-807a-0836f5dc16cb",
   "metadata": {},
   "source": [
    "## Create observations for ngmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64ff256-ca4a-4a8e-9183-69abfc3be5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def observer(batch,shear_true):\n",
    "  psf_fwhm = 0.7\n",
    "  psf = galsim.Moffat(beta=2.5, fwhm=psf_fwhm).shear(g1=g_psf[0],g2=g_psf[1])\n",
    "  psf_image = tf.convert_to_tensor(psf.drawImage(nx=stamp_size, ny=stamp_size, scale=scale,method='no_pixel').array)[tf.newaxis]\n",
    "  psf_images = tf.repeat(psf_image,batch_size,axis=0)\n",
    "\n",
    "  gal_images =amc.noiseless_real_mcal_image(onebatch['gal_model'],\n",
    "                                         psf_images,\n",
    "                                         tf.repeat([shear_true],\n",
    "                                        len(onebatch['gal_model']),axis=0))\n",
    "\n",
    "  noise_img = np.random.normal(scale=noise_level,size=[batch_size,stamp_size,stamp_size])\n",
    "  gal_images += noise_img\n",
    "  psf_noise_img = np.random.normal(scale=psf_noise_level,size=[batch_size,stamp_size,stamp_size])\n",
    "  psf_images += psf_noise_img\n",
    "  obslist = []\n",
    "  for im, psf_im in zip(gal_images,psf_images):\n",
    "    cen = (np.array(im.shape)-1.0)/2.0\n",
    "    psf_cen = (np.array(psf_im.shape)-1.0)/2.0\n",
    "\n",
    "    jacobian = ngmix.DiagonalJacobian(\n",
    "        row=cen[0] + 0/scale, col=cen[1] + 0/scale, scale=scale,\n",
    "    )\n",
    "    psf_jacobian = ngmix.DiagonalJacobian(\n",
    "        row=psf_cen[0], col=psf_cen[1], scale=scale,\n",
    "    )\n",
    "    wt = im*0 + 1.0/noise_level**2\n",
    "    psf_wt = psf_im*0 + 1.0/psf_noise_level**2\n",
    "\n",
    "    psf_obs = ngmix.Observation(\n",
    "        psf_im,\n",
    "        weight=psf_wt,\n",
    "        jacobian=psf_jacobian,\n",
    "    )\n",
    "\n",
    "    obs = ngmix.Observation(\n",
    "        im,\n",
    "        weight=wt,\n",
    "        jacobian=jacobian,\n",
    "        psf=psf_obs,\n",
    "    )\n",
    "    obslist += [obs]\n",
    "  \n",
    "  return obslist  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba8c1d-2d35-49c5-abc2-8970a5dfd276",
   "metadata": {},
   "source": [
    "## Make the ngmix runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d1f1d7-50a1-42aa-8bf2-0f12086c0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngmix_booter_moments(rng,**kwargs):\n",
    "  options = {\n",
    "    'psf': 'dilate',\n",
    "    'types': ['noshear', \n",
    "              '1p', '1m', '2p', '2m', '1p_psf', '1m_psf', '2p_psf', '2m_psf'\n",
    "              ],\n",
    "    'scale': scale,\n",
    "        \n",
    "  }\n",
    "\n",
    "  weight_fwhm = 1.2\n",
    "  fitter = ngmix.gaussmom.GaussMom(fwhm=weight_fwhm)\n",
    "  psf_fitter = ngmix.gaussmom.GaussMom(fwhm=weight_fwhm)\n",
    "\n",
    "  # these \"runners\" run the measurement code on observations\n",
    "  psf_runner = ngmix.runners.PSFRunner(fitter=psf_fitter)\n",
    "  runner = ngmix.runners.Runner(fitter=fitter)\n",
    " \n",
    "  boot = ngmix.metacal.MetacalBootstrapper(\n",
    "      runner=runner,\n",
    "      psf_runner=psf_runner,\n",
    "      rng=rng,\n",
    "      psf=options['psf'],\n",
    "      types=options['types'],\n",
    "    fixnoise = False\n",
    "  )\n",
    "  return boot\n",
    "\n",
    "boot = ngmix_booter_moments(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce184ff-7f49-4cad-9a70-e248c133729a",
   "metadata": {},
   "source": [
    "...and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84be3a4-b385-4f51-8028-46cb664aac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngmix_step(obs):\n",
    "  resdict, _ = boot.go(obs)\n",
    "  return resdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c0ff1-c08d-4ec1-9e4b-f28e4fd5d577",
   "metadata": {},
   "source": [
    "## Extract the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a66703-c45e-43a6-a7fb-ac00e3449c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metacal_response_ngmix(resdict):\n",
    "  step=0.01\n",
    "\n",
    "  #shear\n",
    "  g0s = np.array([resdict['noshear']['g'][0], resdict['noshear']['g'][1]])\n",
    "  g1p = np.array([resdict['1p']['g'][0], resdict['1p']['g'][1]])\n",
    "  g1m = np.array([resdict['1m']['g'][0], resdict['1m']['g'][1]])\n",
    "  g2p = np.array([resdict['2p']['g'][0], resdict['2p']['g'][1]])\n",
    "  g2m = np.array([resdict['2m']['g'][0], resdict['2m']['g'][1]])    \n",
    "  \n",
    "  R11 = (g1p[0]-g1m[0])/(2*step)\n",
    "  R21 = (g1p[1]-g1m[1])/(2*step) \n",
    "  R12 = (g2p[0]-g2m[0])/(2*step)\n",
    "  R22 = (g2p[1]-g2m[1])/(2*step)\n",
    "  \n",
    "  #PSF\n",
    "  g1p_psf = np.array([resdict['1p_psf']['g'][0], resdict['1p_psf']['g'][1]])\n",
    "  g1m_psf = np.array([resdict['1m_psf']['g'][0], resdict['1m_psf']['g'][1]])\n",
    "  g2p_psf = np.array([resdict['2p_psf']['g'][0], resdict['2p_psf']['g'][1]])\n",
    "  g2m_psf = np.array([resdict['2m_psf']['g'][0], resdict['2m_psf']['g'][1]])    \n",
    "  \n",
    "  R11_psf = (g1p_psf[0]-g1m_psf[0])/(2*step)\n",
    "  R21_psf = (g1p_psf[1]-g1m_psf[1])/(2*step) \n",
    "  R12_psf = (g2p_psf[0]-g2m_psf[0])/(2*step)\n",
    "  R22_psf = (g2p_psf[1]-g2m_psf[1])/(2*step)  \n",
    "  \n",
    "  ellip_dict = {\n",
    "    'noshear':g0s,\n",
    "    '1p':g1p,\n",
    "    '1m':g1m,\n",
    "    '2p':g2p,\n",
    "    '2m':g2m,\n",
    "    '1p_psf':g1p_psf,\n",
    "    '1m_psf':g1m_psf,\n",
    "    '2p_psf':g2p_psf,\n",
    "    '2m_psf':g2m_psf,    \n",
    "  } \n",
    "  \n",
    "  R = np.array(\n",
    "    [[R11,R12],\n",
    "     [R21,R22]])\n",
    "\n",
    "  Rpsf = np.array(\n",
    "    [[R11_psf,R12_psf],\n",
    "     [R21_psf,R22_psf]])\n",
    "    \n",
    "  return ellip_dict, R, Rpsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e558ebe5-0bea-458f-ab96-6cf2ad7d95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metacal_response_ngmix_moments(resdict):\n",
    "  step=0.01\n",
    "\n",
    "  #shear\n",
    "  g0s = np.array([resdict['noshear']['e'][0], resdict['noshear']['e'][1]])\n",
    "  g1p = np.array([resdict['1p']['e'][0], resdict['1p']['e'][1]])\n",
    "  g1m = np.array([resdict['1m']['e'][0], resdict['1m']['e'][1]])\n",
    "  g2p = np.array([resdict['2p']['e'][0], resdict['2p']['e'][1]])\n",
    "  g2m = np.array([resdict['2m']['e'][0], resdict['2m']['e'][1]])    \n",
    "  \n",
    "  R11 = (g1p[0]-g1m[0])/(2*step)\n",
    "  R21 = (g1p[1]-g1m[1])/(2*step) \n",
    "  R12 = (g2p[0]-g2m[0])/(2*step)\n",
    "  R22 = (g2p[1]-g2m[1])/(2*step)\n",
    "  \n",
    "  #PSF\n",
    "  g1p_psf = np.array([resdict['1p_psf']['e'][0], resdict['1p_psf']['e'][1]])\n",
    "  g1m_psf = np.array([resdict['1m_psf']['e'][0], resdict['1m_psf']['e'][1]])\n",
    "  g2p_psf = np.array([resdict['2p_psf']['e'][0], resdict['2p_psf']['e'][1]])\n",
    "  g2m_psf = np.array([resdict['2m_psf']['e'][0], resdict['2m_psf']['e'][1]])    \n",
    "  \n",
    "  R11_psf = (g1p_psf[0]-g1m_psf[0])/(2*step)\n",
    "  R21_psf = (g1p_psf[1]-g1m_psf[1])/(2*step) \n",
    "  R12_psf = (g2p_psf[0]-g2m_psf[0])/(2*step)\n",
    "  R22_psf = (g2p_psf[1]-g2m_psf[1])/(2*step)  \n",
    "  \n",
    "  ellip_dict = {\n",
    "    'noshear':g0s,\n",
    "    '1p':g1p,\n",
    "    '1m':g1m,\n",
    "    '2p':g2p,\n",
    "    '2m':g2m,\n",
    "    '1p_psf':g1p_psf,\n",
    "    '1m_psf':g1m_psf,\n",
    "    '2p_psf':g2p_psf,\n",
    "    '2m_psf':g2m_psf,    \n",
    "  } \n",
    "  \n",
    "  R = np.array(\n",
    "    [[R11,R12],\n",
    "     [R21,R22]])\n",
    "\n",
    "  Rpsf = np.array(\n",
    "    [[R11_psf,R12_psf],\n",
    "     [R21_psf,R22_psf]])\n",
    "    \n",
    "  return ellip_dict, R, Rpsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edebb50c-3852-440e-a78a-ff2b326cf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacal_shear(e,R):\n",
    "  return linalg.inv(R) @ e\n",
    "\n",
    "def metacal_shear_psf(e,R,ep, Rp):\n",
    "  return linalg.inv(R) @ (e - Rp @ ep)\n",
    "\n",
    "def bootstraper(x,nboot):\n",
    "  resample = random.randint(0,len(x),[nboot,len(x)])\n",
    "  return x[resample].mean(axis=0)\n",
    "  \n",
    "def evaluator(ellips, R, g_psf, Rpsf):\n",
    "  nboot=1000 #bootstraps make it look professional\n",
    "\n",
    "  #uncorrected  \n",
    "  resample = random.randint(0,batch_size,[nboot,batch_size])\n",
    "  e = bootstraper(ellips,nboot).reshape(-1,2,1)\n",
    "  R = bootstraper(R,nboot)\n",
    "  Rp = bootstraper(Rpsf,nboot)\n",
    "\n",
    "  shears = metacal_shear(e,R)\n",
    "  shear = shears.mean(axis=0)\n",
    "  shear_err = shears.std(axis=0)\n",
    "\n",
    "  shearcorrs = metacal_shear_psf(e,R,g_psf.reshape(-1,2,1), Rp)\n",
    "  shearcorr = shearcorrs.mean(axis=0)\n",
    "  shearcorr_err = shearcorrs.std(axis=0)\n",
    "  return shear[...,0], shear_err[...,0],  shearcorr[...,0], shearcorr_err[...,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48bcc2-b973-4f8b-bd1f-dcbc10184d0e",
   "metadata": {},
   "source": [
    "## AutoMetaCal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26126871-33f2-45a3-8632-32b139b09453",
   "metadata": {},
   "source": [
    "We will run with a simple moments-based method for now."
   ]
  },
  {
   "cell_type": "raw",
   "id": "983d1664-623e-403e-b1da-2e04b1b7075f",
   "metadata": {},
   "source": [
    "_INTERPOLATOR = \"bernsteinquintic\"\n",
    "from tensorflow_addons.image import resampler\n",
    " \n",
    "def shearfunc(img,g1,g2,interpolation=_INTERPOLATOR):\n",
    "  \"\"\"\n",
    "   Applies a shear g1, g2 on an image. \n",
    "   \n",
    "   Args: \n",
    "     img: tf.tensor [batch,nx,ny,channels] float32\n",
    "       batch of images\n",
    "     g1, g2: shears to be applied\n",
    "     \n",
    "  Returns:\n",
    "    sheared: tf.tensor [batch,nx,ny,channels]\n",
    "      sheared image\n",
    "\n",
    "  \"\"\"\n",
    "  \n",
    "  _ , nx, ny, _ = img.get_shape().as_list()\n",
    "  g1 = tf.convert_to_tensor(g1, dtype=tf.float32)\n",
    "  g2 = tf.convert_to_tensor(g2, dtype=tf.float32)\n",
    "  gsqr = g1**2 + g2**2\n",
    "  \n",
    "  # Building a batched jacobian\n",
    "  jac = tf.stack([ 1. + g1, g2,\n",
    "                g2, 1. - g1], axis=1) / tf.expand_dims(tf.sqrt(1.- gsqr),1)\n",
    "  jac = tf.reshape(jac, [-1,2,2]) \n",
    "\n",
    "  # Inverting these jacobians to follow the TF definition\n",
    "  if img.dtype == tf.complex64:\n",
    "    transform_matrix = tf.transpose(jac,[0,2,1])\n",
    "  else:\n",
    "    transform_matrix = tf.linalg.inv(jac)\n",
    "  \n",
    "  #define a grid at pixel positions\n",
    "  warp = tf.stack(tf.meshgrid(tf.linspace(0.,tf.cast(nx,tf.float32)-1.,nx), \n",
    "                              tf.linspace(0.,tf.cast(ny,tf.float32)-1.,ny)),axis=-1)[..., tf.newaxis]\n",
    "\n",
    "  #get center\n",
    "  center = tf.convert_to_tensor([[nx/2],[ny/2]],dtype=tf.float32)\n",
    "  \n",
    "  #displace center to origin\n",
    "  warp = warp - center\n",
    "  \n",
    "  #if fourier, no half pixel shift needed\n",
    "  warp -= int(img.dtype != tf.complex64)*.5\n",
    "\n",
    "  #apply shear\n",
    "  warp = tf.matmul(transform_matrix[:, tf.newaxis, tf.newaxis, ...], warp)[...,0]\n",
    "\n",
    "  #return center\n",
    "  warp = warp + center[...,0] \n",
    " \n",
    "  #if fourier, no half pixel shift needed\n",
    "  warp -= int(img.dtype != tf.complex64)*.5\n",
    "      \n",
    "  #apply resampler\n",
    "  if img.dtype == tf.complex64:\n",
    "    a = resampler(tf.math.real(img),warp,interpolation)\n",
    "    b = resampler(tf.math.imag(img),warp,interpolation)\n",
    "    sheared = tf.complex(a,b)\n",
    "  else:\n",
    "    sheared = resampler(img,warp,interpolation)\n",
    "  return sheared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb26e28a-fddc-497a-afd8-df8a0e5b3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def observer_amc(batch,shear_true):\n",
    "  \"\"\"makes observations for amc from galaxy models\"\"\"\n",
    "  psf_fwhm = 0.7\n",
    "  psf = galsim.Moffat(beta=2.5, fwhm=psf_fwhm).shear(g1=g_psf[0],g2=g_psf[1])\n",
    "  psf_image = tf.convert_to_tensor(psf.drawImage(nx=stamp_size, ny=stamp_size, scale=scale,method='no_pixel').array)[tf.newaxis]\n",
    "  psf_images = tf.repeat(psf_image,batch_size,axis=0)\n",
    "\n",
    "  gal_images =amc.noiseless_real_mcal_image(onebatch['gal_model'],\n",
    "                                         psf_images,\n",
    "                                         tf.repeat([shear_true],\n",
    "                                        len(onebatch['gal_model']),axis=0))\n",
    "\n",
    "  noise_img = np.random.normal(scale=noise_level,size=[batch_size,stamp_size,stamp_size])\n",
    "  gal_images += noise_img\n",
    "  psf_noise_img = np.random.normal(scale=psf_noise_level,size=[batch_size,stamp_size,stamp_size])\n",
    "  psf_images += psf_noise_img\n",
    "  \n",
    "  return gal_images, psf_images  \n",
    "gal_images, psf_images = observer_amc(onebatch,array([0.01,.0],dtype='float32'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "282d4cf6-506b-4985-b8d4-de476e7c3e18",
   "metadata": {},
   "source": [
    "def dilate(img,factor,interpolator=_INTERPOLATOR):\n",
    "  \"\"\" Dilate images by some factor, preserving the center. \n",
    "  \n",
    "  Args:\n",
    "    img: tf tensor containing [batch_size, nx, ny, channels] images\n",
    "    factor: dilation factor (factor >= 1)\n",
    "  \n",
    "  Returns:\n",
    "    dilated: tf tensor containing [batch_size, nx, ny, channels] images dilated by factor around the centre\n",
    "  \"\"\"\n",
    "  img = tf.convert_to_tensor(img,dtype=tf.float32)\n",
    "  batch_size, nx, ny, _ = img.get_shape()\n",
    "\n",
    "  #x\n",
    "  sampling_x = tf.linspace(0.,tf.cast(nx,tf.float32)-1.,nx)[tf.newaxis]\n",
    "  centred_sampling_x = sampling_x - nx//2\n",
    "  batched_sampling_x = tf.repeat(centred_sampling_x,batch_size,axis=0)\n",
    "  rescale_sampling_x = tf.transpose(batched_sampling_x) / factor\n",
    "  reshift_sampling_x = tf.transpose(rescale_sampling_x)+nx//2\n",
    "  #y\n",
    "  sampling_y = tf.linspace(0.,tf.cast(ny,tf.float32)-1.,ny)[tf.newaxis]\n",
    "  centred_sampling_y = sampling_y - ny//2\n",
    "  batched_sampling_y = tf.repeat(centred_sampling_y,batch_size,axis=0)\n",
    "  rescale_sampling_y = tf.transpose(batched_sampling_y) / factor\n",
    "  reshift_sampling_y = tf.transpose(rescale_sampling_y)+ny//2\n",
    "\n",
    "  meshx = tf.transpose(tf.repeat([reshift_sampling_x],nx,axis=0),[1,0,2])\n",
    "  meshy = tf.transpose(tf.transpose(tf.repeat([reshift_sampling_y],ny,axis=0)),[1,0,2])\n",
    "  warp = tf.transpose(tf.stack([meshx,meshy]),[1,2,3,0])\n",
    "\n",
    "  dilated= resampler(img,warp,interpolator)\n",
    "  \n",
    "  return tf.transpose(tf.transpose(dilated) /factor**2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d398e19-7bfc-477e-90aa-02b5407b6184",
   "metadata": {},
   "source": [
    "#new autometacal\n",
    "\n",
    "def makekpsf(psf,dtypes='complex64'):\n",
    "  psf_complex = tf.cast(psf, dtype=dtypes)\n",
    "  psf_fft = tf.signal.fft2d(psf_complex)\n",
    "  psf_fft_abs = tf.abs(psf_fft)\n",
    "  psf_fft_abs_complex = tf.cast(psf_fft_abs,dtype=dtypes)\n",
    "  kpsf = tf.signal.fftshift(psf_fft_abs_complex,axes=[1,2])\n",
    "  \n",
    "  return kpsf\n",
    "\n",
    "def generate_mcal_image(gal_images,\n",
    "                        psf_images,\n",
    "                        reconvolution_psf_images,\n",
    "                        g, gp,\n",
    "                        padfactor=3):\n",
    "  \"\"\" Generate a metacalibrated image given input and target PSFs.\n",
    "  \n",
    "  Args: \n",
    "    gal_images: tf.Tensor or np.array\n",
    "      (batch_size, N, N ) image of galaxies\n",
    "    psf_images: tf.Tensor or np.array\n",
    "      (batch_size, N, N ) image of psf model\n",
    "    reconvolution_psf_image: tf.Tensor\n",
    "      (N, N ) tensor of reconvolution psf model\n",
    "    g: tf.Tensor or np.array\n",
    "    [batch_size, 2] input shear\n",
    "  Returns:\n",
    "    img: tf.Tensor\n",
    "      tf tensor containing image of galaxy after deconvolution by psf_deconv, \n",
    "      shearing by g, and reconvolution with reconvolution_psf_image.\n",
    "  \n",
    "  \"\"\"\n",
    "  #cast stuff as float32 tensors\n",
    "  batch_size, nx, ny = gal_images.get_shape().as_list() \n",
    "  g = tf.convert_to_tensor(g, dtype=tf.float32)  \n",
    "  gal_images = tf.convert_to_tensor(gal_images, dtype=tf.float32)  \n",
    "  psf_images = tf.convert_to_tensor(psf_images, dtype=tf.float32)\n",
    "  reconvolution_psf_image = tf.convert_to_tensor(reconvolution_psf_images, dtype=tf.float32)\n",
    "  \n",
    "  #dilate reconvolution psf\n",
    "  dilate_fact = 1. + 2.*tf.reduce_sum(g**2,axis=1)\n",
    "  reconvolution_psf_image = dilate(reconvolution_psf_image[...,tf.newaxis],dilate_fact)[...,0]\n",
    "  \n",
    "  #pad images\n",
    "  fact = (padfactor - 1)//2 #how many image sizes to one direction\n",
    "  paddings = tf.constant([[0, 0,], [nx*fact, nx*fact], [ny*fact, ny*fact]])\n",
    "  gal_images = tf.pad(gal_images,paddings)\n",
    "  psf_images = tf.pad(psf_images,paddings)\n",
    "  reconvolution_psf_images = tf.pad(reconvolution_psf_image,paddings)\n",
    "  \n",
    "  #Convert galaxy images to k space\n",
    "  im_shift = tf.signal.ifftshift(gal_images,axes=[1,2]) # The ifftshift is to remove the phase for centered objects\n",
    "  im_complex = tf.cast(im_shift, tf.complex64)\n",
    "  im_fft = tf.signal.fft2d(im_complex)\n",
    "  imk = tf.signal.fftshift(im_fft, axes=[1,2])#the fftshift is to put the 0 frequency at the center of the k image\n",
    "  \n",
    "  #Convert psf images to k space  \n",
    "  kpsf = makekpsf(psf_images)\n",
    "\n",
    "  #Convert reconvolution psf image to k space \n",
    "  krpsf = makekpsf(reconvolution_psf_images)\n",
    "\n",
    "  # Compute Fourier mask for high frequencies\n",
    "  # careful, this is not exactly the correct formula for fftfreq\n",
    "  kx, ky = tf.meshgrid(tf.linspace(-0.5,0.5,padfactor*nx),\n",
    "                       tf.linspace(-0.5,0.5,padfactor*ny))\n",
    "  mask = tf.cast(tf.math.sqrt(kx**2 + ky**2) <= 0.5, dtype='complex64')\n",
    "  mask = tf.expand_dims(mask, axis=0)\n",
    "  \n",
    "  # Deconvolve image from input PSF\n",
    "  im_deconv = imk /(kpsf+1e-10) * mask\n",
    "\n",
    "  # Apply shear to the  deconv image\n",
    "  im_sheared = shearfunc(tf.expand_dims(im_deconv,-1), g[...,0], g[...,1])[...,0]  \n",
    "\n",
    "  # Apply shear to the  kpsf image\n",
    "  krpsf_sheared = shearfunc(tf.expand_dims(krpsf,-1), gp[...,0], gp[...,1])[...,0]    \n",
    "  \n",
    "  # Reconvolve with target PSF\n",
    "  im_reconv = tf.signal.ifft2d(tf.signal.ifftshift(im_sheared * krpsf_sheared * mask ))\n",
    "\n",
    "  # Compute inverse Fourier transform\n",
    "  img = tf.math.real(tf.signal.fftshift(im_reconv))\n",
    "  return img[:,fact*nx:-fact*nx,fact*ny:-fact*ny]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01d05cb5-cc9e-43a1-a9d7-a8f7a1d11c3e",
   "metadata": {},
   "source": [
    "def get_metacal_response(gal_images,\n",
    "                         psf_images,\n",
    "                         reconvolution_psf_image,\n",
    "                         method):\n",
    "  \"\"\"\n",
    "  Convenience function to compute the shear response\n",
    "  \"\"\"  \n",
    "  gal_images = tf.convert_to_tensor(gal_images, dtype=tf.float32)\n",
    "  psf_images = tf.convert_to_tensor(psf_images, dtype=tf.float32)\n",
    "  batch_size, _ , _ = gal_images.get_shape().as_list()\n",
    "  g = tf.zeros([batch_size, 2])\n",
    "  gp = tf.zeros([batch_size, 2])\n",
    "  epsf = method(reconvolution_psf_image)\n",
    "  with tf.GradientTape() as tape:\n",
    "    with tf.GradientTape() as tape2:\n",
    "      tape.watch(gp)\n",
    "      tape2.watch(g)\n",
    "      # Measure ellipticity under metacal\n",
    "      e = method(generate_mcal_image(gal_images,\n",
    "                                     psf_images,\n",
    "                                     psf_images,\n",
    "                                     g,gp))\n",
    "\n",
    "  Rpsf = tape.batch_jacobian(e, gp)\n",
    "  R = tape2.batch_jacobian(e, g)  \n",
    "  #R, Rpsf = Rs[...,0:2], Rs[...,2:4]\n",
    "  return e, epsf, R, Rpsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f11a2b39-3195-40bc-9bcb-ad07499bc2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AutoMetaCal runner\n",
    "method = lambda im: amc.get_moment_ellipticities(im, scale=scale, fwhm=1.2)\n",
    "\n",
    "#for amc\n",
    "@tf.function\n",
    "def response(gal_images,psf_images):\n",
    "  return amc.python.metacal_psf.get_metacal_response(gal_images, psf_images,psf_images,method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a1b5ea-cf9b-4994-a0a5-c52c8cfc7df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    }
   ],
   "source": [
    "e_amc, e_psf, R_auto, R_psf = amc.python.metacal_psf.get_metacal_response(gal_images, psf_images,psf_images,method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d87c6db-ac31-4acb-8f28-41d6d1846cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear, shear_err, shearcorr, shearcorr_err= evaluator(e_amc.numpy(), R_auto.numpy() ,e_psf.numpy(), R_psf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a91102-8e34-44d3-a0b5-c44a4af48891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMetaCal\n",
      "-------------------------------------------------\n",
      "With psf correction:\n",
      "shear: 0.00622 +/- 0.02224149 (99.7%% conf)\n",
      "-------------------------------------------------\n",
      "Without psf correction:\n",
      "shear: 0.01108 +/- 0.02224068 (99.7%% conf)\n"
     ]
    }
   ],
   "source": [
    "print('AutoMetaCal')\n",
    "print('-------------------------------------------------')\n",
    "print('With psf correction:')\n",
    "print(f\"shear: {shearcorr[0]:.5f} +/- {shearcorr_err[0]*3:.8f} (99.7%% conf)\")\n",
    "print('-------------------------------------------------')\n",
    "print('Without psf correction:')\n",
    "print(f\"shear: {shear[0]:.5f} +/- {shear_err[0]*3:.8f} (99.7%% conf)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0400c8-c439-45a7-9e94-61cfd5179fed",
   "metadata": {},
   "source": [
    "## Many batches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7c1cd-a729-40d5-8788-6c71b270a87c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Addons>ResamplerGrad\n"
     ]
    }
   ],
   "source": [
    "shear_range = linspace(-.02,.02,3)\n",
    "\n",
    "shear_ngmix_list = []\n",
    "shear_err_ngmix_list = []\n",
    "shearcorr_ngmix_list = []\n",
    "shearcorr_err_ngmix_list = []\n",
    "\n",
    "shear_amc_list = []\n",
    "shear_err_amc_list = []\n",
    "shearcorr_amc_list = []\n",
    "shearcorr_err_amc_list = []\n",
    "\n",
    "import tqdm\n",
    "for shear in tqdm.tqdm(shear_range):\n",
    "  shear_true = array([shear,0.],dtype='float32')  \n",
    "    \n",
    "  #batches to fit in memory\n",
    "  e_ngmix_list = []\n",
    "  R_ngmix_list = []\n",
    "  Rpsf_ngmix_list = []\n",
    "  e_amc_list = []\n",
    "  R_amc_list = []\n",
    "  Rpsf_amc_list = []\n",
    "  \n",
    "  for i in range(20):\n",
    "    onebatch = batchit.next()\n",
    "    obslist = observer(onebatch,shear_true)\n",
    "\n",
    "    #print(f\"Parallel running ngmix in {ncpus}  processes...\")\n",
    "    pool = Pool(ncpus)\n",
    "    dlist = pool.map(ngmix_step,obslist)\n",
    "    pool.close()\n",
    "    #print(\"Done!\")  \n",
    "\n",
    "    #REXtractor (REsults eXtractor! :))\n",
    "    results = [get_metacal_response_ngmix_moments(resdict) for resdict in dlist]\n",
    "    \n",
    "    #stack results ngmix\n",
    "    e_ngmix_list += [result[0]['noshear'] for result in results]\n",
    "    R_ngmix_list += [result[1] for result in results]\n",
    "    Rpsf_ngmix_list += [result[2] for result in results]\n",
    "\n",
    "\n",
    "    #AutoMetaCal\n",
    "    gal_images, psf_images  = observer_amc(onebatch,shear_true)\n",
    "    e_amc, e_psf, R_auto, R_psf = response(gal_images, psf_images)\n",
    "    \n",
    "    #stack results amc\n",
    "    e_amc_list += [e_amc]\n",
    "    #e_psf_list += [e_psf]\n",
    "    R_amc_list +=[R_auto]\n",
    "    Rpsf_amc_list += [R_psf]\n",
    "  \n",
    "  e_ngmix = array(e_ngmix_list)\n",
    "  R_ngmix = array(R_ngmix_list)\n",
    "  #g_psf = \n",
    "  Rpsf_ngmix = array(Rpsf_ngmix_list)\n",
    "  \n",
    "  shear_ngmix, shear_err_ngmix, shearcorr_ngmix, shearcorr_err_ngmix= evaluator(e_ngmix, \n",
    "                                                                                  R_ngmix,\n",
    "                                                                                  g_psf, \n",
    "                                                                                  Rpsf_ngmix)\n",
    "  \n",
    "  e_amc = tf.concat(e_amc_list,axis=0)\n",
    "  R_amc = tf.concat(R_amc_list,axis=0)\n",
    "  #g_psf =\n",
    "  Rpsf_amc = tf.concat(Rpsf_amc_list,axis=0)\n",
    "  \n",
    "  shear_amc, shear_err_amc, shearcorr_amc, shearcorr_err_amc= evaluator(e_amc.numpy(), \n",
    "                                                                          R_amc.numpy() ,\n",
    "                                                                          g_psf,\n",
    "                                                                          Rpsf_amc.numpy())\n",
    "  \n",
    "  #gather field result  \n",
    "  shear_ngmix_list += [shear_ngmix]\n",
    "  shear_err_ngmix_list += [shear_err_ngmix]\n",
    "  shearcorr_ngmix_list += [shearcorr_ngmix]\n",
    "  shearcorr_err_ngmix_list += [shearcorr_err_ngmix]\n",
    "\n",
    "  shear_amc_list += [shear_amc]\n",
    "  shear_err_amc_list += [shear_err_amc]\n",
    "  shearcorr_amc_list += [shearcorr_amc]\n",
    "  shearcorr_err_amc_list += [shearcorr_err_amc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58234a1a-7a56-45a9-a8b7-2a68907dde76",
   "metadata": {},
   "source": [
    "## Gather Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820c288-47c3-409d-b7e0-842bc78880a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ec69f-8d90-41ad-b510-67831b892de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')\n",
    "figure(figsize=(6,5))\n",
    "\n",
    "X1 = shear_range\n",
    "Y1 =  array(shear_ngmix_list)[:,0]\n",
    "Y1err = array(shear_err_ngmix_list)[:,0]\n",
    "\n",
    "#biases\n",
    "ngmix_bias = linregress(X1,Y1)\n",
    "m_ngmix = 1-ngmix_bias.slope\n",
    "c_ngmix = ngmix_bias.intercept\n",
    "\n",
    "#errors\n",
    "m_ngmix_err = ngmix_bias.stderr\n",
    "c_ngmix_err = ngmix_bias.intercept_stderr\n",
    "\n",
    "plot_text = f\"Test name: {settings_name}\\n\\n\"\n",
    "\n",
    "plot_text +=  f\"ngmix: m = {m_ngmix:.3e} +/- {m_ngmix_err:.3e}\\n\"\n",
    "plot_text += f\"ngmix: c = {c_ngmix:.3e} +/- {c_ngmix_err:.3e}\\n\"\n",
    "\n",
    "\n",
    "errorbar(X1,Y1 - X1,Y1err*3,fmt='o',label= 'ngmix moments')\n",
    "\n",
    "Y1 =  array(shear_amc_list)[:,0] \n",
    "Y1err = array(shear_err_ngmix_list)[:,0]\n",
    "\n",
    "m_amc = 1-linregress(X1,Y1)[0]\n",
    "c_amc = linregress(X1,Y1)[1]\n",
    "\n",
    "#biases\n",
    "amc_bias = linregress(X1,Y1)\n",
    "m_amc = 1-amc_bias.slope\n",
    "c_amc = amc_bias.intercept\n",
    "\n",
    "#errors\n",
    "m_amc_err = amc_bias.stderr\n",
    "c_amc_err = amc_bias.intercept_stderr\n",
    "\n",
    "errorbar(X1,Y1 - X1,Y1err*3,fmt='o',label= 'amc moments')\n",
    "\n",
    "plot_text += f\"\\namc: m = {m_amc:.3e} +/- {m_amc_err:.3e}\\n\"\n",
    "plot_text += f\"amc: c = {c_amc:.3e} +/- {c_amc_err:.3e}\\n\"\n",
    "\n",
    "figtext(.95,.5 ,plot_text,fontsize=15)\n",
    "\n",
    "xlabel('$g_1$ true')\n",
    "ylabel('residuals')\n",
    "\n",
    "legend(loc=3)\n",
    "title(f'R calibrated')\n",
    "savefig(f'{results_folder}/uncorrected_shear_residuals_{settings_name}.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7e32a-5139-451f-bf9b-fa61591f9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')\n",
    "figure(figsize=(6,5))\n",
    "\n",
    "X1 = shear_range\n",
    "Y1 =  array(shearcorr_ngmix_list)[:,0]\n",
    "Y1err = array(shearcorr_err_ngmix_list)[:,0]\n",
    "\n",
    "#biases\n",
    "ngmix_bias = linregress(X1,Y1)\n",
    "m_ngmix = 1-ngmix_bias.slope\n",
    "c_ngmix = ngmix_bias.intercept\n",
    "\n",
    "#errors\n",
    "m_ngmix_err = ngmix_bias.stderr\n",
    "c_ngmix_err = ngmix_bias.intercept_stderr\n",
    "\n",
    "plot_text = f\"Test name: {settings_name}\\n\\n\"\n",
    "\n",
    "plot_text +=  f\"ngmix: m = {m_ngmix:.3e} +/- {m_ngmix_err:.3e}\\n\"\n",
    "plot_text += f\"ngmix: c = {c_ngmix:.3e} +/- {c_ngmix_err:.3e}\\n\"\n",
    "\n",
    "\n",
    "errorbar(X1,Y1 - X1,Y1err*3,fmt='o',label= 'ngmix moments')\n",
    "\n",
    "Y1 =  array(shearcorr_amc_list)[:,0] \n",
    "Y1err = array(shearcorr_err_ngmix_list)[:,0]\n",
    "\n",
    "m_amc = 1-linregress(X1,Y1)[0]\n",
    "c_amc = linregress(X1,Y1)[1]\n",
    "\n",
    "#biases\n",
    "amc_bias = linregress(X1,Y1)\n",
    "m_amc = 1-amc_bias.slope\n",
    "c_amc = amc_bias.intercept\n",
    "\n",
    "#errors\n",
    "m_amc_err = amc_bias.stderr\n",
    "c_amc_err = amc_bias.intercept_stderr\n",
    "\n",
    "errorbar(X1,Y1 - X1,Y1err*3,fmt='o',label= 'amc moments')\n",
    "\n",
    "plot_text += f\"\\namc: m = {m_amc:.3e} +/- {m_amc_err:.3e}\\n\"\n",
    "plot_text += f\"amc: c = {c_amc:.3e} +/- {c_amc_err:.3e}\\n\"\n",
    "\n",
    "figtext(.95,.5 ,plot_text,fontsize=15)\n",
    "\n",
    "xlabel('$g_1$ true')\n",
    "ylabel('residuals')\n",
    "\n",
    "legend(loc=3)\n",
    "title(f'R calib + Rpsf corr')\n",
    "savefig(f'{results_folder}/bcorrected_shear_residuals_{settings_name}.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee95f1-df04-4511-970d-eb7172534f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,5))\n",
    "subplot(121)\n",
    "hist((Rpsf_amc - Rpsf_ngmix)[:,0,0].numpy().flatten(),alpha=0.7,bins=60, label='$R_{psf,11}$');\n",
    "hist((Rpsf_amc - Rpsf_ngmix)[:,1,1].numpy().flatten(),alpha=0.7,bins=60, label='$R_{psf,22}$');\n",
    "legend(fontsize=15)\n",
    "xlabel('$R_{psf,amc} - R_{psf,ngmix}$',fontsize=15)\n",
    "title(f'diagonal psf responsivity at g1={shear}')\n",
    "subplot(122)\n",
    "ylabel(settings_name,fontsize=20)\n",
    "hist((Rpsf_amc - Rpsf_ngmix)[:,0,1].numpy().flatten(),alpha=0.7,bins=60, label='$R_{psf,12}$');\n",
    "hist((Rpsf_amc - Rpsf_ngmix)[:,1,0].numpy().flatten(),alpha=0.7,bins=60, label='$R_{psf,21}$');\n",
    "legend(fontsize=15)\n",
    "xlabel('$R_{psf,amc} - R_{psf,ngmix}$',fontsize=15)\n",
    "title(f'off-diagonal psf responsivity at g1={shear}')\n",
    "savefig(f'{results_folder}/Rpsf_{settings_name}.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179c6d0-fd07-4abc-b4bf-fb7240c31771",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,5))\n",
    "subplot(121)\n",
    "hist((R_amc - R_ngmix)[:,0,0].numpy().flatten(),alpha=0.7,bins=60, label='$R_{11}$');\n",
    "hist((R_amc - R_ngmix)[:,1,1].numpy().flatten(),alpha=0.7,bins=60, label='$R_{22}$');\n",
    "legend(fontsize=15)\n",
    "xlabel('$R_{amc} - R_{ngmix}$',fontsize=15)\n",
    "title(f'diagonal responsivity at g1={shear}')\n",
    "subplot(122)\n",
    "ylabel(settings_name,fontsize=20)\n",
    "hist((R_amc - R_ngmix)[:,0,1].numpy().flatten(),alpha=0.7,bins=60, label='$R_{12}$');\n",
    "hist((R_amc - R_ngmix)[:,1,0].numpy().flatten(),alpha=0.7,bins=60, label='$R_{21}$');\n",
    "legend(fontsize=15)\n",
    "xlabel('$R_{amc} - R_{ngmix}$',fontsize=15)\n",
    "title(f'off-diagonal responsivity at g1={shear}')\n",
    "savefig(f'{results_folder}/R_{settings_name}.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dedac-e581-4734-bbb8-48cd4f01d076",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b73441-1a0f-4b5a-98f4-369eab2a85ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f2f72-d97e-420c-b485-eec4b894c805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
